omit.table.layout = "n"
)
#Interaction Model by Religion
model_2012_9 <- lm(log_avg_masked_rad_2012 ~ log_muslim + log_otherrel + log_village_area + daily_power_hours + state_name + log_muslim:state_name + log_otherrel:state_name, (data = data_03))
# adding clustered standard errors
vcov_cluster_9 <- vcovHC(model_2012_9, type = "HC")
#R Output
stargazer(model_2012_9, title = "", type="text", se = list(vcov_cluster_9), "vcov")
#Latex Output
stargazer(model_2012_9,
title = "",
type = "latex",
se = list(vcov_cluster_9),
header = FALSE,
digits = 3,
font.size = "small",
align = TRUE,
star.cutoffs = c(0.05, 0.01, 0.001),
omit.table.layout = "n"
)
#Interaction Model by Caste
model_2012_10 <- lm(log_avg_masked_rad_2012 ~ log_SC + log_ST + log_village_area + daily_power_hours + state_name + log_SC:state_name + log_ST:state_name, (data = data_03))
# adding clustered standard errors
vcov_cluster_10 <- vcovHC(model_2012_10, type = "HC")
#R Output
stargazer(model_2012_10, title = "", type="text")
#Latex Output
stargazer(model_2012_10,
title = "",
type = "latex",
se = list(vcov_cluster_10),
header = FALSE,
digits = 3,
font.size = "small",
align = TRUE,
star.cutoffs = c(0.05, 0.01, 0.001),
omit.table.layout = "n"
)
pmodel1 <- pdata %>%
plm(log_avg_rad ~ log_SC + log_ST,
index = c( "uid", "year"), model = "within",  data=.)
# Model 3 Caste
##SC
pmodel3 <- pdata %>%
plm(log_avg_rad ~ log_SC*log_literate + log_SC*log_female + log_num_households,
index = c( "uid", "year"), model = "within",  data=.)
pdata <- read.csv("./Data/Thesis_Panel.csv")
# Add the proportion table to the data frame
pdata <- pdata %>%
mutate(pop_ST_prop = round((pop_ST / total_pop) * 100,2),
pop_SC_prop = round((pop_SC / total_pop) * 100,2),
pop_others_prop = round((pop_others / total_pop) * 100,2),
pop_lit_prop = round((pop_literate / total_pop) * 100,2),
pop_muslim_prop = round((pop_muslim / total_pop) * 100,2),
pop_hindu_prop = round((pop_hindu / total_pop) * 100,2),
pop_otherrel_prop = round((pop_otherrel / total_pop) * 100,2),
pop_rel_minorities_prop = round(((pop_muslim + pop_otherrel)/total_pop)*100, 2),
pop_cas_minorities_prop = round(((pop_ST + pop_SC)/total_pop)*100,2))
# Make dummy variables for SC, ST, and Muslim dominant population
pdata  <- pdata  %>% #identify change
group_by(year, subdistrict_id)%>%
mutate(Major_SC = ifelse(pop_SC_prop >= 0.5,  Major_SC <- 1, Major_SC <- 0), # the subdistrict has over 50% SC population or not
Major_ST = ifelse(pop_ST_prop>= 0.5, Major_ST <- 1, Major_ST <- 0), # the subdistrict has over 50% ST population or not
Major_muslim = ifelse(pop_muslim_prop >= 0.5, Major_muslim <- 1, Major_muslim <- 0), # the subdistrict has over 50% muslim population or not
Major_hindu = ifelse(pop_hindu_prop >= 0.5, Major_hindu <- 1, Major_hindu <- 0)) #the subdistrict has over 50% hindu population or not
# Add log transformed columns for all population data and for nightlight radiance
pdata <- pdata %>%
mutate(log_SC = log(pop_SC), log_ST = log1p(pop_ST), log_muslim = log(pop_muslim), log_literate= log(pop_literate), log_hindu= log(pop_hindu), log_others = log(pop_others), log_otherrel = log(pop_otherrel), log_avg_rad = log1p(ntl_avg_masked_rad), log_total_pop = log(total_pop), log_male = log(pop_male), log_female = log(pop_female), log_village_area = log(village_area_hectares))
# Check for duplicate observations
duplicates <- duplicated(pdata)
# Print the number of duplicate observations
cat("Number of duplicate observations: ", sum(duplicates))
modelnew <- pdata %>% filter(year==2012)
#coplot( log_literate~ log_num_households|state_name, type="b", data=modelnew)
model_2012_check <- lm(log_avg_rad ~ log_SC + log_ST + log_muslim + log_literate + state_name + power_use_all + daily_power_hours, (data = modelnew))
stargazer(model_2012_check, title = "", type="text")
LState <- pdata %>% ggplot(., aes(x=state_name, y=log_avg_rad)) +
geom_point() +
xlab("State") +
ylab("log Annual electricity consumption")
LYear <- pdata %>% ggplot(., aes(x=year, y=log_avg_rad)) +
geom_point() +
xlab("Year") +
ylab("log Annual electricity consumption")
LMuslim <- ggplot(pdata, aes(x = log_muslim, y = log_avg_rad)) +
geom_point() +
xlab("log of Muslim Population") +
ylab("log Annual electricity consumption")
LHindu <- ggplot(pdata, aes(x = log_hindu, y = log_avg_rad)) +
geom_point() +
xlab("log of Hindu Population") +
ylab("log Annual electricity consumption")
LSC <- ggplot(pdata, aes(x = log_SC, y = log_avg_rad)) +
geom_point() +
xlab("log of SC Population") +
ylab("log Annual electricity consumption")
LST <- ggplot(pdata, aes(x = log_ST, y = log_avg_rad)) +
geom_point() +
xlab("log of ST Population") +
ylab("log Annual electricity consumption")
#to be included
fe_scatterplot <- grid.arrange(LState, LYear, LMuslim, LHindu, LSC, LST,  nrow = 3, ncol = 2)
fe_scatterplot
##corelation plots
coplot(ntl_avg_masked_rad ~ year|state_name, type="b", data=pdata)
#heterogeneity between the states
png(height=600, width=600, pointsize = 15,
file= here("Output","NTLstate.png"), type = "cairo")
NTLstate <- plotmeans(ntl_avg_masked_rad ~ state_name, main="Heterogeineity across states", data=pdata)
dev.off()
#heterogeneity between the years
png(height=600, width=600, pointsize = 15,
file= here("Output","NTLyears.png"), type = "cairo")
NTLyears <- plotmeans(ntl_avg_masked_rad ~ year, main="Heterogeineity across years", data=pdata)
dev.off()
LState <- pdata %>% ggplot(., aes(x=state_name, y=log_avg_rad)) +
geom_point() +
xlab("State") +
ylab("log Annual electricity consumption")
LYear <- pdata %>% ggplot(., aes(x=year, y=log_avg_rad)) +
geom_point() +
xlab("Year") +
ylab("log Annual electricity consumption")
LMuslim <- ggplot(pdata, aes(x = log_muslim, y = log_avg_rad)) +
geom_point() +
xlab("log of Muslim Population") +
ylab("log Annual electricity consumption")
LHindu <- ggplot(pdata, aes(x = log_hindu, y = log_avg_rad)) +
geom_point() +
xlab("log of Hindu Population") +
ylab("log Annual electricity consumption")
LSC <- ggplot(pdata, aes(x = log_SC, y = log_avg_rad)) +
geom_point() +
xlab("log of SC Population") +
ylab("log Annual electricity consumption")
LST <- ggplot(pdata, aes(x = log_ST, y = log_avg_rad)) +
geom_point() +
xlab("log of ST Population") +
ylab("log Annual electricity consumption")
#to be included
fe_scatterplot <- grid.arrange(LState, LYear, LMuslim, LHindu, LSC, LST,  nrow = 3, ncol = 2)
fe_scatterplot
##corelation plots
coplot(ntl_avg_masked_rad ~ year|state_name, type="b", data=pdata)
#heterogeneity between the states
png(height=600, width=600, pointsize = 15,
file= here("Output","NTLstate.png"), type = "cairo")
NTLstate <- plotmeans(ntl_avg_masked_rad ~ state_name, main="Heterogeineity across states", data=pdata)
dev.off()
#heterogeneity between the years
png(height=600, width=600, pointsize = 15,
file= here("Output","NTLyears.png"), type = "cairo")
NTLyears <- plotmeans(ntl_avg_masked_rad ~ year, main="Heterogeineity across years", data=pdata)
dev.off()
#Model 1 = Statewise electricity consumption
fe_oneway <- pdata%>%
plm(log_avg_rad ~ state_name +  log_literate +log_female + log_male,
index = c( "year", "uid"), model = "within", data=.)
fe_twoway <- pdata%>%
plm(log_avg_rad ~ state_name +  log_literate +log_female + log_male,
index = c( "year", "uid"), model = "within",  data=.)
#summary(pmodel1)
#OLS model
ols <-lm(log_avg_rad ~ as.factor(state_name), data=pdata)
summary(ols)
#test on OLS vs Fixed effects model
pFtest(fe_oneway, ols)
#random model
random <- plm(log_avg_rad ~ as.factor(state_name) +  log_literate +log_female + log_male,
index = c( "year", "uid"), model = "random", data=pdata)
summary(random)
##test on random vs fixed effects model
phtest(fe_oneway, random)
phtest(fe_twoway, random)
#coeftest specific small sample correction, sss type for reporting clustered standard error:
### coeftest(pmodel1, function(x) vcovHC(x, type = 'sss'))
#coeftest for reporting clustered standard error:
### coeftest(pmodel1, vcovHC(pmodel1, type = 'HC0', cluster = 'group'))
#Function for getting beta and se dataframe
beta_sed_df <- function(p, limit=10) {
betas <- numeric(limit)
for (i in seq_along(betas)) {
betas[i] <- p$coefficients[i]
}
se <- sqrt(diag(vcovHC(p, method = "arellano", cluster="group")))
sed <- as.vector(se)
sed <- sed[1:limit]
year <- c(2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021)
d <- data.frame(beta = betas, sed = sed, year)
return(d)
}
##defining distance for graphs
pd <- position_dodge(width = 0.3)
#1. Breusch-Pagan test for Homoskedacity, p-value < 0.05, alternative hypothesis: heteroskedacity
bptest(log_avg_rad~state_name + as.factor(uid), data = pdata, studentize = FALSE)
#2.	Breusch-Godfrey/Wooldridge test for serial correlation in panel models, p-value < 0.05, alternative hypothesis: serial correlation in idiosyncratic errors
#pbgtest(pmodel1)
###With clustering standard errors
pmodel1 <- pdata %>%
plm(log_avg_rad ~ state_name,
index = c( "year", "uid"), model = "within", data=.)
summary(pmodel1)
pmodel2 <- pdata %>%
plm(log_avg_rad ~ state_name*log_male,
index = c( "year", "uid"), model = "within",   data=.)
pmodel3 <- pdata %>%
plm(log_avg_rad ~ state_name*log_literate,
index = c( "year", "uid"), model = "within",   data=.)
pmodel4 <- pdata %>%
plm(log_avg_rad ~ state_name*log_village_area,
index = c( "year", "uid"), model = "within",   data=.)
stargazer(pmodel1, pmodel2, pmodel3, pmodel4,  title = " ", type = "text")
cluster1 <- vcovHC(pmodel1, method = "arellano", cluster="group")
cluster2 <- vcovHC(pmodel2, method = "arellano", cluster="group")
cluster3 <- vcovHC(pmodel3, method = "arellano", cluster="group")
cluster4 <- vcovHC(pmodel4, method = "arellano", cluster="group")
stargazer(pmodel1, pmodel2, pmodel3, pmodel4,  title = "FE Regression for State-level", type = "text",
se = list(cluster1, cluster2, cluster3, cluster4), omit.stat = c("f", "ser"),
star.cutoffs = c(0.05, 0.01, 0.001), header = FALSE)
stargazer(pmodel1, pmodel2, pmodel3, pmodel4,
title = "",
type = "latex",
se = list(cluster1, cluster2, cluster3, cluster4),
omit.stat = c("f", "ser"),
header = FALSE,
digits = 3,
font.size = "small",
align = TRUE,
star.cutoffs = c(0.05, 0.01, 0.001),
omit.table.layout = "n" )
##Models for appendix
pmodel1 <- pdata %>%
plm(log_avg_rad ~ state_name*as.factor(year),
index = c( "year", "uid"), model = "within", data=.)
summary(pmodel1)
#Model1 = By religion
#1. Breusch-Pagan test for Homoskedacity, p-value < 0.05, alternative hypothesis: heteroskedacity
bptest(log_avg_rad~log_muslim + as.factor(uid), data = pdata, studentize = FALSE)
#2.	Breusch-Godfrey/Wooldridge test for serial correlation in panel models, p-value < 0.05, alternative hypothesis: serial correlation in idiosyncratic errors
pbgtest(pmodel)
###With clustering standard errors
pmodel1 <- pdata %>%
plm(log_avg_rad ~ log_muslim*log_female + log_muslim*log_literate ,
model = "within", index = c("uid", "year"),  data=.)
cluster1 <- vcovHC(pmodel1, method = "arellano", cluster="group")
pmodel2 <- pdata %>%
plm(log_avg_rad ~ log_otherrel*log_female + log_otherrel*log_literate ,
model = "within", index = c("uid", "year"),   data=.)
cluster2 <- vcovHC(pmodel2, method = "arellano", cluster="group")
pmodel3 <- pdata %>%
plm(log_avg_rad ~ log_muslim*log_village_area + log_otherrel*log_village_area + daily_power_hours + power_use_all + log_hindu*log_village_area,
index = c( "year", "uid"), model = "within",   data=.)
cluster3 <- vcovHC(pmodel3, method = "arellano", cluster="group")
stargazer(pmodel1, pmodel2, pmodel3,  title = "FE Regression for Religions", type = "text",
se = list(cluster1, cluster2, cluster3), omit.stat = c("f", "ser"),
star.cutoffs = c(0.05, 0.01, 0.001), header = FALSE)
stargazer(pmodel1, pmodel2, pmodel3,  title = "FE Regression for Religions", type = "text",
se = list(cluster1, cluster2, cluster3), omit.stat = c("f", "ser"),
star.cutoffs = c(0.05, 0.01, 0.001), header = FALSE)
stargazer(pmodel1, pmodel2, pmodel3,
title = "",
type = "latex",
se = list(cluster1, cluster2, cluster3),
header = FALSE,
digits = 3,
font.size = "small",
align = TRUE,
star.cutoffs = c(0.05, 0.01, 0.001),
omit.table.layout = "n" )
# Model 3 Caste
##SC
pmodel3 <- pdata %>%
plm(log_avg_rad ~ log_SC*log_literate + log_SC*log_female + log_num_households,
index = c( "uid", "year"), model = "within",  data=.)
pmodel4 <- pdata %>%
plm(log_avg_rad ~ log_ST*log_literate + log_ST*log_female + log_num_households,
index = c( "uid", "year"), model = "within",  data=.)
# Model 3 Caste
##SC
pmodel3 <- pdata %>%
plm(log_avg_rad ~ log_SC*log_literate + log_SC*log_female ,
index = c( "uid", "year"), model = "within",  data=.)
summary(pmodel3)
#1. Breusch-Pagan test for Homoskedacity, p-value < 0.05, alternative hypothesis: heteroskedacity
bptest(log_avg_rad~log_SC + as.factor(uid), data = pdata, studentize = FALSE)
#1. Breusch-Pagan test for Homoskedacity, p-value < 0.05, alternative hypothesis: heteroskedacity
bptest(log_avg_rad~log_SC + as.factor(uid), data = pdata, studentize = FALSE)
#2.	Breusch-Godfrey/Wooldridge test for serial correlation in panel models, p-value < 0.05, alternative hypothesis: serial correlation in idiosyncratic errors
pbgtest(pmodel3)
coeftest(pmodel3, vcovHC(pmodel3, method = "arellano", cluster="group"))
pmodel4 <- pdata %>%
plm(log_avg_rad ~ log_ST*log_literate + log_ST*log_female ,
index = c( "uid", "year"), model = "within",  data=.)
summary(pmodel4)
pmodel1 <- pdata %>%
plm(log_avg_rad ~ log_SC + log_ST,
index = c( "uid", "year"), model = "within",  data=.)
cluster1 <- vcovHC(pmodel1, method = "arellano", cluster="group")
pmodel2 <- pdata %>%
plm(log_avg_rad ~ log_SC*log_village_area + log_SC*log_female + log_SC*log_literate ,
index = c( "uid", "year"), model = "within",  data=.)
cluster2 <- vcovHC(pmodel2, method = "arellano", cluster="group")
pmodel3 <- pdata %>%
plm(log_avg_rad ~ log_ST*log_village_area + log_ST*log_literate + log_ST*log_female,
index = c( "uid", "year"), model = "within",  data=.)
cluster3 <- vcovHC(pmodel3, method = "arellano", cluster="group")
pmodel4 <- pdata %>%
plm(log_avg_rad ~ log_SC*log_village_area + log_SC*log_female + log_SC*log_literate + log_ST*log_village_area + log_ST*log_literate + log_ST*log_female ,
index = c( "uid", "year"), model = "within",  data=.)
cluster4 <- vcovHC(pmodel4, method = "arellano", cluster="group")
stargazer(pmodel1, pmodel2, pmodel3, pmodel4,  title = "FE Regression for Caste", type = "text",
se = list(cluster1, cluster2, cluster3, cluster4),
star.cutoffs = c(0.05, 0.01, 0.001), header = FALSE)
stargazer(pmodel1, pmodel2, pmodel3, pmodel4,
title = "",
type = "latex",
se = list(cluster1, cluster2, cluster3, cluster4),
header = FALSE,
digits = 3,
font.size = "small",
align = TRUE,
star.cutoffs = c(0.05, 0.01, 0.001),
omit.table.layout = "n" )
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
mydata <- read.csv("data/ACLED_countries.csv",
stringsAsFactors = F)
View(mydata)
setwd("/Users/hibaahmad/Documents/IDS Fall 2023/Labs/labs")
?mean
?mean
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
4*9
sqrt(144)
abs(-3)
4 > 2
4 <= 2
result <- 5/3
result
result <- 5-3
result
my_vector <- c(1, 2, 3)
my_character_vector <- c("Welcome", "everyone")
my_list <- list(1, "a", TRUE)
my_vector <- (1, 2, 3)
my_vector <- c(1, 2, 3)
my_character_vector <- c("Welcome", "everyone")
length(my_vector)
str(my_character_vector)
str(my_list)
my_matrix_2 <- matrix(4,3)
dim(my_matrix)
my_matrix <- matrix(nrow=3, ncol=3)
dim(my_matrix)
my_df <- data.frame(id = letters[1:10], x = 1:10, y = 11:20)
my_df
dim(my_df)
head(my_df)
tail(my_df)
nrow(my_df)
ncol(my_df)
str(my_df)
names(my_df)
# turning vectors into factors
my_vector <- c("single","single","married","married","single")
my_factor <- as.factor(my_vector)
# direct creation of factors
my_factor <- factor(c("single","single","married","married","single"))
levels(my_factor)
pop1 <- c(1379, 1324, 323, 261, 208)
pop1
pop2 <- c(194, 187, 161, 142, 127)
pop <- c(pop1, pop2)
pop
str(pop)
cname <- c("CHN", "IND", "USA", "IDN", "BRA")
str(cname)
asia <- c(TRUE, TRUE, F, T, F)
str(asia)
regime <- c("Autocracy", "FlawedDem", "FullDem", "FlawedDem", "FlawedDem")
regime <- c("Autocracy", "FlawedDem", "FullDem", "FlawedDem", "FlawedDem")
str(regime)
regime <- as.factor(regime)
str(regime)
regime <- factor(c("Autocracy", "FlawedDem", "FullDem", "FlawedDem", "FlawedDem"))
str(regime)
regime <- as.character(regime)
str(regime)
asia <- as.character(asia)
str(asia)
asia <- as.logical(asia)
str(asia)
no_good <- c(a,b,c)
yes_good <- c("a","b","c")
no_good_either <- c(one, two, three)
no_good_either <- c("one", "two", "three")
vec <- c("1", "2", "3")
str(vec)
pop1
pop1_double <- pop1 * 2
pop1_double
res <- pop1 + pop2
pop1
pop2
res <- pop1 + pop2
res
pop_c <- c(pop1, pop2)
pop_c
min(pop)
max(pop)
mean(pop)
mean(pop)
sum(pop)/length(pop)
pop1
pop1[1]
pop1[4]
cname[1]
pop[c(2,5)]
cname[c(2,5)]
first <- pop[1]
length(pop)
first <- pop[length(pop)]
first
pop[length(pop)]
regime
regime[2] <- "FullDem"
regime
pop
pop[3] <- pop[3] - 10
pop
pop[c(3,5)] <- pop[c(3,5)] - 10
pop
cindex <- seq(from = 1, to = length(pop1), by = 1)
cindex
seq(1,5,1)
seq(2, 10, 2)
rep(30, 5)
completed <- rep(c("no","yes"), 5)
completed
completed2 <- rep(c("yes","no"), each = 5)
completed2
pop1
names(pop1)
cname
names(pop1) <- cname
names(pop1)
pop1
pop1[names(pop1) == "BRA"]
pop1[pop1 >= mean(pop1)]
pop1[pop1 < max(pop1) & names(pop1) != "USA"]
cname == "IDN"
regime[cname == "IDN"]
which(cname == "IDN")
regime[which(cname == "IDN")]
pop1[asia == T & regime != "Autocracy"]
pop1[asia == T | regime != "Autocracy"]
pop1[asia == T | regime != "Autocracy"]
install.packages("foreign")
#install.packages("foreign") #alternatively use "Install" button
library(foreign)
mydata <- read.csv("data/ACLED_countries.csv")
View(mydata)
mydata <- read.csv("data/ACLED_countries.csv",
stringsAsFactors = F)
mydata <- read.csv("data/ACLED_countries.csv",
stringsAsFactors = F)
str(mydata)
names(mydata)
names(mydata)[3] <- "nconflict"
names(mydata)
summary(mydata)
nrow(mydata) # Number of rows
ncol(mydata) # Number of columns
dim(mydata) # Rows first then columns.
mydata[1, ]
mydata[c(1,2), ]
mydata[1:5,]
mydata[3,7]
mydata[1,1]
mydata[100,3]
which(colnames(mydata) == "nconflict")
mydata[,3]
mydata$nconflict
table(mydata$region)
summary(mydata$nconflict)
table(mydata$region, mydata$nconflict > mean(mydata$nconflict))
mydata[,1]
max(mydata$nconflict)
max(mydata$nconflict)
mydata$country[mydata$conflict == max(mydata$nconflict)]
mydata$country[mydata$nconflict == max(mydata$nconflict)]
mydata$country
mydata$country[seq(2, length(mydata$country), 2)]
vec <- c(4, 1, 2, NA, 3)
mean(vec) #Result is NA!
sum(vec) #Result is NA!
mean(vec, na.rm = T)
sum(vec, na.rm = T)
mydata
dim(mydata)
obs <- c("Germany", "Europe", NA, NA, NA)
mydata_new <- rbind(mydata, obs)
dim(mydata_new)
mydata$nconflict_fatalities <- mydata$nconflict - mydata$nconflict_no_fatalities
head(mydata, 3) #prints out the first 3 rows of the data frame
mydata$av_fatalities <- mydata$fatalities/mydata$nconflict
mydata_na <- mydata[mydata$region == "Northern Africa",]
max(mydata_na$nconflict)
mydata_na$country[mydata_na$nconflict == max(mydata_na$nconflict)]
getwd()
## Saving data
Suppose we wanted to save this newly created data frame. We have multiple options to do so. If we wanted to save it as a native `.RData` format, we would run the following command.
getwd()
